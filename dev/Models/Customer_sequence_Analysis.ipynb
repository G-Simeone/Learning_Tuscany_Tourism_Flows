{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Analysis\n",
    "\n",
    "The objective of this notebook is to\n",
    "1. Create sequences from trajectories for customers\n",
    "2. Load sequences into R package TraMineR\n",
    "3. Use TraMineR functions to calculate distance between sequences using TRATE or 2-1-1 costs\n",
    "4. Cluster the distance matrix using PAM/k-medoids clustering\n",
    "5. Plot medoid trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rpy2\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from connect_db import db_connection\n",
    "\n",
    "# filter annyoing warning from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username='kmohan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_location = '/mnt/data/'+username+'/utils/data_creds_redshift.json.nogit'\n",
    "db = db_connection.DBConnection(cred_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for the 1week sample\n",
    "\n",
    "query = \"\"\"\n",
    "select customer_nr, com_locs_new as locations,times_new as times, st_time,en_time, mcc \n",
    "from tuscany.customer_arrays\n",
    "where times_new is not null\n",
    "and st_time >= '2017-06-01 00:00:00' and st_time < '2017-09-01 00:00:00'\n",
    "and mcc = 262\n",
    "\"\"\"\n",
    "# drop 'customer_id' to save memory\n",
    "df_trips = db.sql_query_to_data_frame(query, cust_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = max(df_trips['en_time'] - df_trips['st_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(max_time.total_seconds()/(60*60*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = max(df_trips['en_time'] - df_trips['st_time'])\n",
    "ncols = math.ceil(max_time.total_seconds()/(60*60*12))\n",
    "columns = np.linspace(1,ncols,ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cus = df_trips.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips['times'] = df_trips['times'].str.split(', ').tolist()\n",
    "df_trips['locations'] = df_trips['locations'].str.split(', ').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_array(row):\n",
    "    return len(row['locations'])\n",
    "\n",
    "def len_times(row):\n",
    "    return len(row['times'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_nr = df_trips['customer_nr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_lens = df_trips.apply(len_array,axis=1)\n",
    "time_lens = df_trips.apply(len_times,axis=1)\n",
    "cus_nr = df_trips['customer_nr']\n",
    "\n",
    "df_lens = pd.DataFrame({'customer_nr':cus_nr,'com_len' : com_lens, 'time_len': time_lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday 0 to Sunday 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lens['diff'] = df_lens['com_len'] - df_lens['time_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_cus = df_lens[df_lens['diff'] != 1]['customer_nr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filt_cus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = 10*np.linspace(1,6,6)\n",
    "days= np.linspace(0,6.5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.add.outer(weeks,days).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence = pd.DataFrame(columns=columns,index=cus_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_with_max_time(array_like):\n",
    "    return np.bincount(array_like).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(cus_nr)):\n",
    "#    print(i)\n",
    "    df_row = df_trips[i:i+1]\n",
    "    cus = df_row['customer_nr'][i]\n",
    "    st_wk = df_row['st_time'][i].weekday()\n",
    "    st_hr = df_row['st_time'][i].hour\n",
    "    country = df_row['mcc'][i]\n",
    "    # Initialising all values on the sequence to be country of origin\n",
    "    df_sequence.loc[[cus],columns[:]] = country\n",
    "    times = [0]\n",
    "    minutes = [0]\n",
    "    timestamps = [df_row['st_time'][i]]\n",
    "    cum_mins = np.cumsum(np.array(list(map(int,df_row['times'][i]))))\n",
    "    minutes.extend(np.array(list(map(int,df_row['times'][i]))))\n",
    "    times.extend(np.cumsum(np.array(list(map(int,df_row['times'][i])))))\n",
    "    timestamps.extend(np.datetime64(df_row['st_time'][i]) + cum_mins.astype('timedelta64[m]'))\n",
    "    coms = np.array(df_row['com_locs'][i])\n",
    "    tmp_df = pd.DataFrame({'Minutes' : minutes, 'Mins_cum' : times, 'Locations': coms, 'Timestamps':timestamps })\n",
    "    tmp_df['date'] = tmp_df['Timestamps'].dt.date\n",
    "    ts = pd.Series(coms,dtype=np.int64,index=tmp_df['Timestamps'])\n",
    "    ts = ts.resample('1T').bfill()\n",
    "    ts2 = ts.resample('12H').apply(location_with_max_time)\n",
    "    col_idx_st = 2*st_wk + int(st_hr/12)\n",
    "    df_sequence.loc[[cus],columns[col_idx_st:(col_idx_st + len(ts2))]] = ts2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.loc[:,columns[74:84]].sort_values(by=[62],ascending=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence_trimmed = df_sequence.loc[:,columns[0:73]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.to_csv(\"../../sequences_Tuscany_Aug_20000_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = df_trips['st_time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = np.datetime64(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_array0 = cum_array0.astype('timedelta64[m]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st + cum_array0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row = df_trips[873:874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row['st_time'][873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df_row['st_time'][873].hour/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus = df_row['customer_nr'][873]\n",
    "st_wk = df_row['st_time'][873].weekday()\n",
    "country = df_row['mcc'][873]\n",
    "times = [0]\n",
    "minutes = [0]\n",
    "timestamps = [df_row['st_time'][873]]\n",
    "cum_mins = np.cumsum(np.array(list(map(int,df_row['times'][873]))))\n",
    "minutes.extend(np.array(list(map(int,df_row['times'][873]))))\n",
    "times.extend(np.cumsum(np.array(list(map(int,df_row['times'][873])))))\n",
    "timestamps.extend(np.datetime64(df_row['st_time'][873]) + cum_mins.astype('timedelta64[m]'))\n",
    "coms = np.array(df_row['com_locs'][873])\n",
    "tmp_df = pd.DataFrame({'Minutes' : minutes, 'Mins_cum' : times, 'Locations': coms, 'Timestamps':timestamps })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['date'] = tmp_df['Timestamps'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(coms,dtype=np.int64,index=tmp_df['Timestamps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.resample('1T').bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['2017-08-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_with_max_time(array_like):\n",
    "    return np.bincount(array_like).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = ts.resample('12H').apply(location_with_max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_hr = df_row['st_time'][0].hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*st_wk + 1 if st_hr >=12 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns[13:(13+59)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.loc[[cus],columns[:]] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence.loc[[cus],columns[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(12)+'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_list_to_int_list(array_like):\n",
    "    return list(map(int,array_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(df_trips):\n",
    "    \"\"\"\n",
    "    Convert a str (output of the SQL query) into a list of strs\n",
    "\n",
    "    Parameters:\n",
    "    df_trips: DataFrame containing the column 'locations' and 'times'\n",
    "    \"\"\"\n",
    "\n",
    "    # replace str of geolocations by a list of strs with geolocation codes\n",
    "    df_trips['locations'] = list(map(str_list_to_int_list,df_trips['locations'].str.split(', ').tolist()))\n",
    "\n",
    "    # replace str of geolocations by a list of strs with geolocation codes\n",
    "    df_trips['times'] = list(map(str_list_to_int_list,df_trips['times'].str.split(', ').tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_list(df_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_with_max_time(array_like):\n",
    "    \"\"\"\n",
    "    Returns the value in array apprearing most frequently\n",
    "\n",
    "    Parameters:\n",
    "    array_like: any array\n",
    "    \"\"\"\n",
    "    return np.bincount(array_like).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_for_individual(i,align_by_day_of_week,window_hrs,country_for_missing,ncols):\n",
    "    # extracting the row for each customer\n",
    "    df_row = df_trips[i:i+1]\n",
    "    cus = int(df_row['customer_nr'][i])\n",
    "    st_wk = df_row['st_time'][i].weekday()\n",
    "    st_hr = df_row['st_time'][i].hour\n",
    "    country = int(df_row['mcc'][i])\n",
    "\n",
    "    seq = [np.nan] * ncols\n",
    "    seq[0] = cus\n",
    "    # Initialising all values on the sequence to be country of origin if set to True\n",
    "    if country_for_missing == True:\n",
    "        seq[1:] = [country]*(ncols-1)\n",
    "\n",
    "    # Creating the Pandas Series object from the list of 'times'\n",
    "    # Initialising the time array\n",
    "    timestamps = [np.datetime64(df_row['st_time'][i])]\n",
    "\n",
    "    # Cummulating times spent at each location to create timestamps\n",
    "    cum_mins = np.cumsum(np.array(list(map(int,df_row['times'][i]))))\n",
    "    timestamps.extend(np.datetime64(df_row['st_time'][i]) + cum_mins.astype('timedelta64[m]'))\n",
    "\n",
    "    # Getting list of locations\n",
    "    locs = np.array(df_row['locations'][i])\n",
    "    # Defining the Pandas Series object\n",
    "    ts = pd.Series(locs,dtype=np.int64,index=timestamps)\n",
    "\n",
    "    # Resampling sequence for the required window size\n",
    "    # 1 minute resolution before resampling to window_hrs as we want to find the location spent maximum time at in the window\n",
    "    ts = ts.resample('1T').bfill()\n",
    "    # Resampling to window_hrs\n",
    "    ts2 = ts.resample(str(window_hrs)+'H').apply(location_with_max_time)\n",
    "\n",
    "    # Identifying the columns to insert into\n",
    "    if align_by_day_of_week == True:\n",
    "        col_idx_st = int(24/window_hrs)*st_wk + int(st_hr/window_hrs)\n",
    "    else:\n",
    "        col_idx_st = int(st_hr/window_hrs)\n",
    "\n",
    "    # Inserting location values into the sequence dataframe\n",
    "    # df_sequence.loc[[cus],columns[col_idx_st:(col_idx_st + len(ts2))]] = ts2.values\n",
    "    seq[col_idx_st:(col_idx_st + len(ts2))] = ts2.values\n",
    "\n",
    "    return seq\n",
    "\n",
    "# TODO: Save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df_trips,align_by_day_of_week=True,window_hrs=3,country_for_missing=True,n_threads=5):\n",
    "    \"\"\"\n",
    "    Create a dataframe of aligned sequences for sequence clustering analysis\n",
    "\n",
    "    Parameters:\n",
    "    df_trips: DataFrame containing the column 'locations', 'times', 'st_time','customer_nr','mcc'\n",
    "    align_by_day_of_week: If True, the sequences are aligned by the day of week of arrival. Else, the sequences are aligned \n",
    "        by their respective first day of arrival.\n",
    "    window_hrs: window size for sequence creation in hours. A sequence would contain a location for every 'window_hrs' \n",
    "        from start to end times\n",
    "    country_for_missing: If True, the location for entries in the sequence when the individual wasn't in Italy would be\n",
    "        set to the MCC code of the respective country\n",
    "    n_threads: Number of threads to use in parallel\n",
    "    \"\"\"    \n",
    "\n",
    "    # importing math for ceiling function\n",
    "    import math\n",
    "    from multiprocessing import Pool\n",
    "    from itertools import repeat\n",
    "    \n",
    "    # finding the maximum time spent by an individual to set the length fo sequence\n",
    "    max_time = max(df_trips['en_time'] - df_trips['st_time'])\n",
    "    ncols = math.ceil(max_time.total_seconds()/(60*60*window_hrs))\n",
    "\n",
    "    # If aligning by day of week of arrival, we need additional columns \n",
    "    # as someone could arrive on a sunday and stay for max_time\n",
    "    if align_by_day_of_week == True:\n",
    "        ncols += 6*math.ceil(24/window_hrs)\n",
    "\n",
    "    # weeks = 10*np.linspace(1,6,6)\n",
    "    # days= np.linspace(0,6.5,14)\n",
    "    # columns = np.add.outer(weeks,days).flatten()\n",
    "    \n",
    "    # Initialising the sequence dataframe with NAs\n",
    "    columns = np.linspace(1,ncols,ncols)\n",
    "    cus_nr = df_trips['customer_nr']\n",
    "    # df_sequence = pd.DataFrame(np.nan,columns=columns,index=cus_nr)\n",
    "\n",
    "    # Looping through every customer array to create the aligned sequences data frame\n",
    "    p = Pool(n_threads)\n",
    "    l = [i for i in range(0,len(cus_nr))]\n",
    "    sequences_as_lists = p.starmap(create_sequence_for_individual, zip(l, [align_by_day_of_week]*len(cus_nr), [window_hrs]*len(cus_nr), [country_for_missing]*len(cus_nr), [ncols+1]*len(cus_nr)))\n",
    "\n",
    "    # Converting list of lists into a dataframe\n",
    "    col_names = ['customer_nr'] + list(map(str,np.linspace(1,ncols,ncols)))\n",
    "    df_sequence = pd.DataFrame.from_records(sequences_as_lists,columns=col_names)\n",
    "\n",
    "    # Setting customer number to be the index\n",
    "    df_sequence = df_sequence.set_index('customer_nr')\n",
    "    return df_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1 = create_sequences(df_trips,align_by_day_of_week=False,window_hrs=12,country_for_missing=True,n_threads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1.to_csv(\"/mnt/data/kmohan/sequences_Germans_Summer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Sequences using TraMineR package in R\n",
    "\n",
    " - loading dataframe saved above into R environment\n",
    " - creating sequence object\n",
    " - substitution cost using TRATE\n",
    " - distance between sequences using OMA\n",
    " - clustering using PAM/k-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages('TraMineR')\n",
    "install.packages('TraMineRextras')\n",
    "install.packages('fpc')\n",
    "install.packages('WeightedCluster')\n",
    "install.packages('foreach')\n",
    "install.packages('parallel')\n",
    "install.packages('doParallel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(cluster)\n",
    "library(lattice)\n",
    "library(TraMineR)\n",
    "library(TraMineRextras)\n",
    "library(fpc)\n",
    "library(foreach)\n",
    "library(parallel)\n",
    "library(doParallel)\n",
    "library(WeightedCluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df_seq <- read.csv(\"../../sequences_Germans_Summer.csv\")\n",
    "agg_seq <- wcAggregateCases(df_seq[,-1])\n",
    "print(agg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "unique_seq <- df_seq[agg_seq$aggIndex, -1]\n",
    "seq_obj <- seqdef(unique_seq, weights = agg_seq$aggWeights)\n",
    "seq_subcost <- seqcost(seq_obj,method=\"CONSTANT\",cval=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "seq_dist <- seqdist(seq_obj,method = \"OM\",sm=seq_subcost$sm,full.matrix=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "seq_dist <- seqdist(seq_obj[2,],refseq=seq_obj[1,],method = \"OM\",sm=seq_subcost$sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "seq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "packageVersion(\"TraMineR\")\n",
    "getRversion()\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "load(\"../../seqdist_Tuscany_Aug_10000_sample.RSav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "## Stats to find number of clusters\n",
    "get_pam_cluster_stats <- function(dist_matrix,k){\n",
    "  cl <- pam(dist_matrix,k=k,diss=TRUE)\n",
    "  cs <- cluster.stats(dist_matrix,clustering = cl$clustering)\n",
    "  return(c(cs$ch,cs$avg.silwidth ))\n",
    "}\n",
    "\n",
    "cl.stats = data.frame(matrix(0,nrow=5,ncol=2))\n",
    "\n",
    "for (i in c(2:10)){\n",
    "    cl.stats[i,] = get_pam_cluster_stats(seq_dist_trate,i)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot(x=c(2:10),y=cl.stats[2:10,1],type='l')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "clusterpam_trate <- pam(seq_dist_trate, k=4, diss = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "clustering_results = data.frame(ids=df_seq[,1], cluster=clusterpam_trate$clustering)\n",
    "write.csv(clustering_results,\"../../clusters_Tuscany_4_Aug_10000_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "medoids_cus_ids = df_seq[clusterpam_trate$medoids,1]\n",
    "write.csv(medoids_cus_ids,\"../../medoids_Tuscany_4_Aug_10000_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "save(seq_dist_trate,file=\"../../seqdist_Tuscany_Aug_10000_sample.RSav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "K<-5\n",
    "for (k in 1:K){\n",
    "    seqdplot(seq_obj[clusterpam_trate$clustering==k,])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with nested foreach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "sim <- function(seq_obj,a,b,sm){\n",
    "    k <- sum(b<=a)\n",
    "    if (k < length(b)){\n",
    "        return (c(rep(NA,k),seqdist(seq_obj[b[(k+1):length(b)],],refseq=seq_obj[a,],method = \"OM\",sm=sm)))                \n",
    "    }else{\n",
    "        return (rep(NA,k))                \n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "no_cores <- 8\n",
    "registerDoParallel(makeCluster(no_cores))\n",
    "\n",
    "N <- dim(seq_obj)[1]\n",
    "G <- 10000\n",
    "avec <- c(1:N)\n",
    "\n",
    "seq_dist <- foreach(a=avec, .combine='cbind') %:%\n",
    "foreach(b=c(1:ceiling(N/G)), .combine='c',.packages = c(\"TraMineR\")) %dopar% {\n",
    "sim(seq_obj,a,c((G*(b-1)+1):min((G*b),N)),seq_subcost$sm)\n",
    "}\n",
    "\n",
    "stopImplicitCluster()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "dim(seq_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "simple_sim <- function(a,b){\n",
    "    return (10*a+b)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "no_cores <- detectCores()\n",
    "registerDoParallel(makeCluster(no_cores))\n",
    "\n",
    "bvec <- c(1:10000)\n",
    "avec <- c(1:1000000)\n",
    "x <- foreach(a=avec, .combine='c') %dopar% simple_sim(a, 10)\n",
    "\n",
    "stopImplicitCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "no_cores <- detectCores()\n",
    "registerDoParallel(makeCluster(no_cores))\n",
    "no_cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and descriptives on cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = pd.read_csv(\"../../mediods_5_Jul_Aug_10000_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cus_nos = np.array(df_med.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cus_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_trips['customer_nr'] == med_cus_nos[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med.merge(df_trips,how='inner', left_on='x', right_on='customer_nr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load maps data \n",
    "\n",
    "# load data from TPT\n",
    "regions = r\"/mnt/data/shared/Boundaries regions and municipalities Italy 2016/Reg2016_WGS84_g/Reg_2016_WGS84_g.shp\"\n",
    "provinces = r\"/mnt/data/shared/Boundaries regions and municipalities Italy 2016/CMProv2016_WGS84_g/CMprov2016_WGS84_g.shp\"\n",
    "municipalities = r\"/mnt/data/shared/Boundaries regions and municipalities Italy 2016/Com2016_WGS84_g/Com2016_WGS84_g.shp\"\n",
    "new_reg =  r\"/mnt/data/shared/ITA_shapefiles/Tus_28districts.shp\"\n",
    "\n",
    "# important cities \n",
    "important_cities_file = r\"/mnt/data/shared/important_cities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mun = gpd.read_file(municipalities)\n",
    "gdf_mun['geometry'] = gdf_mun['geometry'].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(list_of_comunes=False):\n",
    "    '''\n",
    "    Parameters:\n",
    "    \n",
    "        list_of_comunes: list of pro_com (as ints)    \n",
    "    '''\n",
    "    \n",
    "    # comune centroids \n",
    "    df_centroids = pd.read_csv(r\"/mnt/data/shared/comune_centroids.csv\")\n",
    "        \n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    gdf_mun.plot(ax=ax, color='white', edgecolor='gray', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    if list_of_comunes is not False:\n",
    "        \n",
    "        trip = pd.DataFrame(list_of_comunes, columns=['PRO_COM'])\n",
    "        trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "        \n",
    "    plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for the 1week sample\n",
    "\n",
    "query = \"\"\"\n",
    "select customer_nr,com_locs_new from tuscany.customer_arrays\n",
    "where customer_nr in (6830799, 5955872, 1179935, 6804043, 1418535)\n",
    "\"\"\"\n",
    "# drop 'customer_id' to save memory\n",
    "df_clusters = db.sql_query_to_data_frame(query, cust_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters['com_locs_new'] = df_clusters['com_locs_new'].str.split(', ').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    plot_trajectory(list(map(int,df_clusters.iloc[i,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comune centroids \n",
    "df_centroids = pd.read_csv(r\"/mnt/data/shared/comune_centroids.csv\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "gdf_mun.plot(ax=ax, color='white', edgecolor='gray', alpha=0.5)\n",
    "\n",
    "trip = pd.DataFrame(list(map(int,df_clusters.iloc[0,1])), columns=['PRO_COM'])\n",
    "trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "\n",
    "plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "\n",
    "trip = pd.DataFrame(list(map(int,df_clusters.iloc[1,1])), columns=['PRO_COM'])\n",
    "trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "\n",
    "plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "\n",
    "trip = pd.DataFrame(list(map(int,df_clusters.iloc[2,1])), columns=['PRO_COM'])\n",
    "trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "\n",
    "plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "\n",
    "trip = pd.DataFrame(list(map(int,df_clusters.iloc[3,1])), columns=['PRO_COM'])\n",
    "trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "\n",
    "plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "\n",
    "trip = pd.DataFrame(list(map(int,df_clusters.iloc[4,1])), columns=['PRO_COM'])\n",
    "trip = trip.merge(df_centroids, how='inner', left_on='PRO_COM', right_on='pro_com')\n",
    "\n",
    "plt.plot(trip['lat'], trip['lon'], '-o')\n",
    "\n",
    "\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with parallel processing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "\n",
    "X = 0\n",
    "\n",
    "def f(x, y, z):\n",
    "    a = x*y*z\n",
    "    b = x+y+z \n",
    "    return list([a,b])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    l =[i for i in range(0,10)]\n",
    "    y = p.starmap(f, zip([1,2,3], [4,5,6],[7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "names = ['Brown', 'Wilson', 'Bartlett', 'Rivera', 'Molloy', 'Opie']\n",
    "print(product(names, repeat=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'col1': [1], 'col2' : [2]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_by_day_of_week=True,window_hrs=3,country_for_missing=True,ncols=(df_sequence.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_for_individual(i,align_by_day_of_week,window_hrs,country_for_missing,ncols):\n",
    "    # extracting the row for each customer\n",
    "    df_row = df_trips[i:i+1]\n",
    "    cus = int(df_row['customer_nr'][i])\n",
    "    st_wk = df_row['st_time'][i].weekday()\n",
    "    st_hr = df_row['st_time'][i].hour\n",
    "    country = int(df_row['mcc'][i])\n",
    "\n",
    "    seq = [np.nan] * ncols\n",
    "    seq[0] = cus\n",
    "    # Initialising all values on the sequence to be country of origin if set to True\n",
    "    if country_for_missing == True:\n",
    "        seq[1:] = [country] * (ncols-1)\n",
    "\n",
    "    # Creating the Pandas Series object from the list of 'times'\n",
    "    # Initialising the time array\n",
    "    timestamps = [np.datetime64(df_row['st_time'][i])]\n",
    "\n",
    "    # Cummulating times spent at each location to create timestamps\n",
    "    cum_mins = np.cumsum(np.array(list(map(int,df_row['times'][i]))))\n",
    "    timestamps.extend(np.datetime64(df_row['st_time'][i]) + cum_mins.astype('timedelta64[m]'))\n",
    "\n",
    "    # Getting list of locations\n",
    "    locs = np.array(df_row['locations'][i])\n",
    "    # Defining the Pandas Series object\n",
    "    ts = pd.Series(locs,dtype=np.int64,index=timestamps)\n",
    "\n",
    "    # Resampling sequence for the required window size\n",
    "    # 1 minute resolution before resampling to window_hrs as we want to find the location spent maximum time at in the window\n",
    "    ts = ts.resample('1T').bfill()\n",
    "    # Resampling to window_hrs\n",
    "    ts2 = ts.resample(str(window_hrs)+'H').apply(location_with_max_time)\n",
    "\n",
    "    # Identifying the columns to insert into\n",
    "    if align_by_day_of_week == True:\n",
    "        col_idx_st = int(24/window_hrs)*st_wk + int(st_hr/window_hrs)\n",
    "    else:\n",
    "        col_idx_st = int(st_hr/window_hrs)\n",
    "\n",
    "    # Inserting location values into the sequence dataframe\n",
    "    # df_sequence.loc[[cus],columns[col_idx_st:(col_idx_st + len(ts2))]] = ts2.values\n",
    "    seq[col_idx_st:(col_idx_st + len(ts2))] = ts2.values\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df_trips,align_by_day_of_week=True,window_hrs=3,country_for_missing=True,n_threads=5):\n",
    "    \"\"\"\n",
    "    Convert a str (output of the SQL query) into a list of strs\n",
    "\n",
    "    Parameters:\n",
    "    df_trips: DataFrame containing the column 'locations', 'times', 'st_time','customer_nr','mcc'\n",
    "    align_by_day_of_week: If True, the sequences are aligned by the day of week of arrival. Else, the sequences are aligned \n",
    "        by their respective first day of arrival.\n",
    "    window_hrs: window size for sequence creation in hours. A sequence would contain a location for every 'window_hrs' \n",
    "        from start to end times\n",
    "    country_for_missing: If True, the location for entries in the sequence when the individual wasn't in Italy would be\n",
    "        set to the MCC code of the respective country\n",
    "    n_threads: Number of threads to use in parallel\n",
    "    \"\"\"    \n",
    "\n",
    "    # importing math for ceiling function\n",
    "    import math\n",
    "    from multiprocessing import Pool\n",
    "    from itertools import repeat\n",
    "    \n",
    "    # finding the maximum time spent by an individual to set the length fo sequence\n",
    "    max_time = max(df_trips['en_time'] - df_trips['st_time'])\n",
    "    ncols = math.ceil(max_time.total_seconds()/(60*60*window_hrs))\n",
    "\n",
    "    # If aligning by day of week of arrival, we need additional columns \n",
    "    # as someone could arrive on a sunday and stay for max_time\n",
    "    if align_by_day_of_week == True:\n",
    "        ncols += 6*math.ceil(24/window_hrs)\n",
    "\n",
    "    # weeks = 10*np.linspace(1,6,6)\n",
    "    # days= np.linspace(0,6.5,14)\n",
    "    # columns = np.add.outer(weeks,days).flatten()\n",
    "    \n",
    "    # Initialising the sequence dataframe with NAs\n",
    "    columns = np.linspace(1,ncols,ncols)\n",
    "    cus_nr = df_trips['customer_nr']\n",
    "    df_sequence = pd.DataFrame(np.nan,columns=columns,index=cus_nr)\n",
    "\n",
    "    # Looping through every customer array to create the aligned sequences data frame\n",
    "    p = Pool(n_threads)\n",
    "    l = [i for i in range(0,len(cus_nr))]\n",
    "    sequences_as_lists = p.starmap(create_sequence_for_individual, zip(l, [align_by_day_of_week]*len(cus_nr), [window_hrs]*len(cus_nr), [country_for_missing]*len(cus_nr), [ncols+1]*len(cus_nr)))\n",
    "\n",
    "    return sequences_as_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1 = create_sequences(df_trips,align_by_day_of_week=True,window_hrs=3,country_for_missing=True,n_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = max(df_trips['en_time'] - df_trips['st_time'])\n",
    "ncols = math.ceil(max_time.total_seconds()/(60*60*window_hrs))\n",
    "\n",
    "# If aligning by day of week of arrival, we need additional columns \n",
    "# as someone could arrive on a sunday and stay for max_time\n",
    "if align_by_day_of_week == True:\n",
    "    ncols += 6*math.ceil(24/window_hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sequence_for_individual(1,align_by_day_of_week=True,window_hrs=12,country_for_missing=True,ncols=ncols+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [np.nan] * (ncols+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[1:] = [2]*ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_common_subseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.read_csv(\"/mnt/data/kmohan/TPT_tourism/new_codebase/src/models/sequence_analysis/data/sequences/sequences_chinese_pre-summer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tpt]",
   "language": "python",
   "name": "conda-env-tpt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
